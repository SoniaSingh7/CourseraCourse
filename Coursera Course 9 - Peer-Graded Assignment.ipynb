{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Segmenting and Clustering Neighborhoods in Toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Introduction\n\nThis is a peer-graded assignment, which explores and clusters the neighborhoods in Toronto, by scraping data from a website.  Also, we will use the Foursquare API to explore neighborhoods in Toronto, and will use the explore function to get the most common venue categories in each neighborhood, and will then use this feature to group the neighborhoods into clusters. We will use K-means clustering and the Folium library to visualize the neighborhoods in Toronto with the clusters.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Before we get the data and start exploring it, let's download all the dependencies that we will need."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n# All requested packages already installed.\n\nSolving environment: | "
                }
            ],
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\n!pip install bs4\nfrom bs4 import BeautifulSoup\n!pip install lxml\n!pip install html5lib\n!pip install requests\nimport csv\nimport requests\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Start of part 1"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### We will scrape the following Wikipedia page https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M to get information about the Toronto neighborhoods, and will use BeautifulSoup to parse through the information."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "source = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\nsoup = BeautifulSoup(source,'lxml')\n#print(soup.prettify())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Extract the Postal Code, Borough, and Neighborhood information."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "match = soup.find('table',class_='wikitable sortable')\npclist = []\nfor pcall in match.tbody.find_all('td'):\n    postcode = pcall.text\n    pclist.append(postcode)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Start by putting it into a dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "newpclist = []\nfor i,s in enumerate(pclist):\n    #print(s.strip())\n    newpclist.append(s.strip())\npcpd = pd.DataFrame(newpclist)\npcpd.head(7)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### The dataframe will consist of three columns: PostalCode, Borough, and Neighborhood, so we shape the dataframe into 3 columns instead of 1.\n#### Only process the cells that have an assigned borough. Ignore cells with a borough that is 'Not assigned'. To do this, we remove all rows where Borough is equal to 'Not assigned'."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pcdf = pd.DataFrame({'PostalCode':newpclist[0::3],'Borough':newpclist[1::3],'Neighborhood':newpclist[2::3]}, columns=['PostalCode','Borough','Neighborhood'])\n# Alternative way to drop Borough != 'Not assigned'\n#  pcdf = pcdf.set_index('Borough')\n#  pcdf.drop(['Not assigned'], axis = 0,inplace=True)\n\npcdf_to_keep = list(np.array(pcdf['Borough'].values)[np.array(pcdf['Borough']!='Not assigned')])\npcdf = pcdf.loc[pcdf['Borough'].isin(pcdf_to_keep)]\nprint(pcdf.shape)\npcdf.head(10)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### More than one neighborhood can exist in one postal code area. For example, in the table on the Wikipedia page, you will notice that M5A is listed twice and has two neighborhoods: Harbourfront and Regent Park. These two rows will be combined into one row with the neighborhoods separated with a comma."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pcdf2 = pcdf.groupby(['PostalCode', 'Borough'])['Neighborhood'].apply(', '.join).reset_index()\nprint(pcdf2.shape)\npcdf2.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### If a cell has a Borough but a 'Not assigned' Neighborhood, then the Neighborhood will be the same as the Borough. E.g. for the 9th cell in the table on the Wikipedia page, the value of the Borough and the Neighborhood columns will be Queen's Park."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pcdf2.replace({'Neighborhood':'Not assigned'}, {'Neighborhood':pcdf2['Borough']}, inplace=True)\npcdf2.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(pcdf2.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## End of Part 1\n## Start of Part 2\n#### Now that we have built a dataframe of each Postal Code along with the Borough name and Neighborhood names, we need to get the latitude and the longitude coordinates of each Postal Code in order to utilize the Foursquare location data.\n#### Given that the Geocoder Python package https://geocoder.readthedocs.io/index.html was very unreliable, I was not able to get the geographical coordinates of the Postal Codes using the Geocoder package, so used this link to a csv file that has the geographical coordinates of each postal code: http://cocl.us/Geospatial_data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "latlong_df = pd.read_csv('http://cocl.us/Geospatial_data', header=0)\nprint(latlong_df.shape)\nlatlong_df.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Rename the column to match them in both dataframes."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "latlong_df.rename(columns = {\"Postal Code\": \"PostalCode\"}, inplace=True)\nlatlong_df.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Merge the two dataframes to create one combined dataset."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_data = pd.merge(pcdf2, latlong_df, on='PostalCode')\ntoronto_data.head(20)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## End of Part 2\n## Start of Part 3"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Use geopy library to get the latitude and longitude values of Toronto.\n\n#### In order to define an instance of the geocoder, we need to define a user_agent. We will name our agent to_explorer.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#define Toronto's lat and long\naddress = 'Toronto, ON'\ngeolocator = Nominatim(user_agent=\"to_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('latitude: ', latitude, 'longitude: ', longitude)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Validate that the dataset has all Boroughs and Neighborhoods."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('The dataframe has {} boroughs and {} neighborhoods.'.format(\n        len(toronto_data['Borough'].unique()),\n        toronto_data.shape[0]\n    )\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Create a map of Toronto with Boroughs and Neighborhoods superimposed on top."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(toronto_data['Latitude'], toronto_data['Longitude'], toronto_data['Borough'], toronto_data['Neighborhood']):\n    label = 'Borough: {} \\n Neighborhood: {}'.format(borough, neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Define Foursquare Credentials and Version."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's explore the first Postal Code in our dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_data.loc[0, 'PostalCode']"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Get the Postal Code's latitude and longitude values."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neighborhood_latitude = toronto_data.loc[0, 'Latitude'] # neighborhood latitude value\nneighborhood_longitude = toronto_data.loc[0, 'Longitude'] # neighborhood longitude value\n\nneighborhood_name = toronto_data.loc[0, 'PostalCode'] # neighborhood name\n\nprint('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n                                                               neighborhood_latitude, \n                                                               neighborhood_longitude))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Now, let's get the top 100 venues that are near Postal Code M1B within a radius of 500 meters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "radius = 500\nLIMIT = 100\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, VERSION, latitude, longitude, radius, LIMIT)\n# url\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Send the GET request and examine the results."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "results = requests.get(url).json()\nresults"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### All the information is in the items key. Before we proceed, let's create the get_category_type function."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Now we are ready to clean the json and structure it into a pandas dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "venues = results['response']['groups'][0]['items']\nprint(venues)\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's examine how many venues were returned."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's create a function to repeat the same process for all the neighborhoods in Toronto."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        # print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['PostalCode', \n                  'PostalCode Latitude', \n                  'PostalCode Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Now we call the above function on each neighborhood and create a new dataframe called toronto_venues."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_venues = getNearbyVenues(names=toronto_data['PostalCode'],\n                                   latitudes=toronto_data['Latitude'],\n                                   longitudes=toronto_data['Longitude']\n                                  )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's check the size of the resulting dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(toronto_venues.shape)\ntoronto_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's check how many venues were returned for each Postal Code."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_venues.groupby('PostalCode').count()\ntoronto_venues.head(10)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's find out how many unique categories can be curated from all the returned venues."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's analyze each Postal Code area."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['PostalCode'] = toronto_venues['PostalCode'] \n\n# move neighborhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\n\ntoronto_onehot.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### And let's examine the new dataframe size."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_onehot.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Now, let's group rows by Postal Code area and by taking the mean of the frequency of occurrence of each category."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_grouped = toronto_onehot.groupby('PostalCode').mean().reset_index()\ntoronto_grouped.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's confirm the new size."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_grouped.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's print each Postal Code along with the top 5 most common venues."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 5\n\nfor pc in toronto_grouped['PostalCode']:\n    print(\"----\"+pc+\"----\")\n    temp = toronto_grouped[toronto_grouped['PostalCode'] == pc].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's put that into a pandas dataframe.\n\n#### First, let's write a function to sort the venues in descending order."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Now let's create the new dataframe and display the top 10 venues for each Postal Code area."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Postal Code']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Postal Code'] = toronto_grouped['PostalCode']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Run k-means to cluster the Postal Code areas into 5 clusters.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('PostalCode', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's create a new dataframe that includes the cluster as well as the top 10 venues for each Postal Code area."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = toronto_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Postal Code'), on='PostalCode', how='inner')\n\n#toronto_merged[\"Cluster Labels\"] = toronto_merged[\"Cluster Labels\"].fillna(0.0).astype(int)\ntoronto_merged.head(20) "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Finally, let's visualize the resulting clusters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, pc, br, nh, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['PostalCode'], toronto_merged['Borough'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup('Postal Code: ' + str(pc) + ' Borough: ' + br + ' Neighborhood\\(s\\): ' + nh + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Examine Clusters\n#### Start by examining # of unique venues in the top 10s."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\nindicators = ['st', 'nd', 'rd']\n\nfor ind in np.arange(num_top_venues):\n    try:\n        column = '{}{} Most Common Venue'.format(ind+1, indicators[ind])\n        print(column + ': ' + str(len(toronto_merged[column].unique().tolist())))\n    except:\n        column = '{}th Most Common Venue'.format(ind+1)\n        print(column + ': ' + str(len(toronto_merged[column].unique().tolist())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Examining Cluster 0, we see that Coffee Shops, Donut Shops, Cafes, and Bakeries are highlights."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[0] + [1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Examining Cluster 1, we see that it is the only one that selected Cafeteria as the most common venue."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Examining Cluster 2, we see that it is popular for the Garden listed as the most common venue."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Examining Cluster 3, we see that it features more ethnic restaurants."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Examining Cluster 4, we see that it features Park as the most common 1st and 2nd choices of venue."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 4, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## End of part 3"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}